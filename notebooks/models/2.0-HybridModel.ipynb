{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid = markov + hierarchical model\n",
    "1. Generate sequences\n",
    "2. Compute MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-15T01:00:16.260Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from parallelspaper.models import gen_seq_hierarchical, gen_seq_markov, gen_balanced_matrix\n",
    "from parallelspaper.utils import nowstring\n",
    "import parallelspaper.information_theory as it\n",
    "from parallelspaper.config.paths import DATA_DIR\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-15T01:00:16.812Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Hierarchical parameters\n",
    "\n",
    "# how many branches to sample in hierarchical\n",
    "n_subsamples = [2]\n",
    "# how many subsamples to perform\n",
    "depth = 12\n",
    "# how many sequences to use\n",
    "nseq = 1000\n",
    "# alphabet size\n",
    "a_n = 5\n",
    "alphabet = np.arange(a_n)\n",
    "\n",
    "print('seq len ',(np.mean(n_subsamples)**depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:10.611995Z",
     "start_time": "2019-03-03T04:10:10.489018Z"
    }
   },
   "outputs": [],
   "source": [
    "# how many markov items to sample \n",
    "markov_seq_len_range = [2,5]\n",
    "# number of elements in markov alphabet\n",
    "a_n_markov = 25\n",
    "markov_alphabet_items = np.arange(a_n_markov)\n",
    "# the number of sequences can correspond to each hierarchical element\n",
    "markov_n_seq_per_element = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:10.697939Z",
     "start_time": "2019-03-03T04:10:10.614299Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate markov probabilities\n",
    "markov_probs = np.random.rand(a_n_markov**2).reshape((a_n_markov, a_n_markov))**2\n",
    "markov_probs = markov_probs/np.sum(markov_probs, axis = 0)\n",
    "# test it out...\n",
    "gen_seq_markov(markov_alphabet_items, markov_probs, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:10.780766Z",
     "start_time": "2019-03-03T04:10:10.700552Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate hierarchical recursive sampling probability matrix\n",
    "probs = gen_balanced_matrix(ps=[.85,.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:11.080277Z",
     "start_time": "2019-03-03T04:10:10.784373Z"
    }
   },
   "outputs": [],
   "source": [
    "# each leaf in the tree grammar should correspond to a markov generated sequence\n",
    "markov_alphabet = {i:[gen_seq_markov(markov_alphabet_items,\n",
    "                                     markov_probs, \n",
    "                                     np.random.randint(markov_seq_len_range[0], markov_seq_len_range[1])\n",
    "                                    ) for j in range(markov_n_seq_per_element)] for i in markov_alphabet_items}\n",
    "markov_alphabet[alphabet[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:11.085160Z",
     "start_time": "2019-03-03T04:10:11.082109Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "import parallelspaper.information_theory as it\n",
    "n_jobs = 12; verbosity=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:15.453770Z",
     "start_time": "2019-03-03T04:10:11.086942Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample sequences hierarchically\n",
    "seqs_list = tqdm(range(nseq), leave=False)# if nseq < 3 else range(nseq)\n",
    "with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "    sequences = parallel(\n",
    "        delayed(gen_seq_hierarchical)(alphabet, probs, depth, n_subsamples)\n",
    "             for seq in seqs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:17.797992Z",
     "start_time": "2019-03-03T04:10:15.455883Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace each element with Markov sampled sequences\n",
    "seqs = [np.concatenate([markov_alphabet[i][np.random.choice(markov_n_seq_per_element)] for i in seq]) for seq in tqdm(sequences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:17.831430Z",
     "start_time": "2019-03-03T04:10:17.803307Z"
    }
   },
   "outputs": [],
   "source": [
    "len(np.concatenate(seqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:18.024884Z",
     "start_time": "2019-03-03T04:10:17.834742Z"
    }
   },
   "outputs": [],
   "source": [
    "# sequence statistics\n",
    "seq_len = len(np.concatenate(seqs))\n",
    "bout_lens = [len(i) for i in seqs]\n",
    "unique_elements = len(np.unique([np.concatenate(seqs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:18.032328Z",
     "start_time": "2019-03-03T04:10:18.028098Z"
    }
   },
   "outputs": [],
   "source": [
    "# sequential distances to compute MI at\n",
    "distances = np.arange(1,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:18.140408Z",
     "start_time": "2019-03-03T04:10:18.035546Z"
    }
   },
   "outputs": [],
   "source": [
    "MI_DF = pd.DataFrame(columns=['name', 'type', 'rep', 'MI', 'MI_shuff', 'distances',\n",
    "                              'MI_var', 'MI_shuff_var', 'n_elements', 'unique_elements', 'bout_lens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:18.238688Z",
     "start_time": "2019-03-03T04:10:18.142557Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "n_jobs = 12; verbosity=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:36.721020Z",
     "start_time": "2019-03-03T04:10:18.243775Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate MI\n",
    "(MI, var_MI), (MI_shuff, MI_shuff_var) = it.sequential_mutual_information([np.concatenate(seqs)],\n",
    "                                                                          distances,\n",
    "                                                                          n_jobs=n_jobs,\n",
    "                                                                          verbosity=verbosity)\n",
    "# add to MI_DF\n",
    "MI_DF.loc[len(MI_DF)] = ['hybrid', 'full', 0, MI,\n",
    "                         MI_shuff, distances, var_MI, MI_shuff_var, seq_len, unique_elements, bout_lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T04:10:37.873024Z",
     "start_time": "2019-03-03T04:10:37.860048Z"
    }
   },
   "outputs": [],
   "source": [
    "now_string = nowstring()\n",
    "MI_DF.to_pickle(str(DATA_DIR / ('MI_DF/models/hybrid_'+now_string+'.pickle')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
