{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute MI on raw audio\n",
    "- find relevant WAV files for BF, starling, speech\n",
    "- spectrogram wavs\n",
    "- segment files into .01, .1, 1 second chunks\n",
    "- KMEANS cluster those chunks\n",
    "- compute MI\n",
    "- plot MI decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:42.430850Z",
     "start_time": "2019-03-23T01:23:42.428582Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:42.846446Z",
     "start_time": "2019-03-23T01:23:42.432688Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:47.467780Z",
     "start_time": "2019-03-23T01:23:42.848671Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.spectrogramming import spectrogramming as sg\n",
    "from parallelspaper.config.paths import DATA_DIR, FIGURE_DIR\n",
    "from parallelspaper.speech_datasets import LCOL_DICT\n",
    "from parallelspaper.birdsong_datasets import BCOL_DICT\n",
    "from parallelspaper.utils import save_fig\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:47.474093Z",
     "start_time": "2019-03-23T01:23:47.469711Z"
    }
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    # filtering\n",
    "    'highcut':15000,\n",
    "    'lowcut':500,\n",
    "    # spectrograms\n",
    "    'mel_filter': True, # should a mel filter be used?\n",
    "    'num_mels':32, # how many channels to use in the mel-spectrogram\n",
    "    'num_freq':512, # how many channels to use in a spectrogram \n",
    "    'preemphasis':0.97, \n",
    "    'frame_shift_ms':5, # step size for fft\n",
    "    'frame_length_ms':10, # frame length for fft\n",
    "    'min_level_db':-50, # minimum threshold db for computing spe \n",
    "    'spec_thresh_min': -40, # (db)\n",
    "    'ref_level_db':50, # reference db for computing spec\n",
    "    'fmin': 300, # low frequency cutoff for mel filter\n",
    "    'fmax': None, # high frequency cutoff for mel filter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:47.547481Z",
     "start_time": "2019-03-23T01:23:47.475703Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "from parallelspaper import information_theory as it \n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from parallelspaper.hvc_funcs import load_cbin # for loading cbin files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:47.868512Z",
     "start_time": "2019-03-23T01:23:47.549240Z"
    }
   },
   "outputs": [],
   "source": [
    "starling_wavs = glob('../../../animalvocalizationgenerativenet/data/st_wavs/b1077/wavs/*.wav')\n",
    "bf_wavs = glob('/mnt/cube/Datasets/BengaleseFinch/sober/*/gy6or6*.cbin')\n",
    "human_wavs = np.array([[i] for i in glob('/mnt/cube/Datasets/buckeye/s01/*.wav')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:47.934562Z",
     "start_time": "2019-03-23T01:23:47.871720Z"
    }
   },
   "outputs": [],
   "source": [
    "# break bf wavs into day\n",
    "bf_labs = [datetime.strptime(\n",
    "            \"_\".join(label_loc.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-2:]),\n",
    "            \"%d%m%y_%H%M\",\n",
    "        ) for label_loc in bf_wavs]\n",
    "bf_wavs = np.array(bf_wavs)[np.argsort(bf_labs)]\n",
    "bf_labs = np.array(bf_labs)[np.argsort(bf_labs)]\n",
    "bf_days = np.array([lab.strftime('%d%m%y') for lab in bf_labs])\n",
    "bf_day_wavs = [bf_wavs[bf_days == i] for i in np.unique(bf_days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:47.995025Z",
     "start_time": "2019-03-23T01:23:47.938178Z"
    }
   },
   "outputs": [],
   "source": [
    "# break starling wavs into day\n",
    "st_labs = [datetime.strptime(i[:-4].split('/')[-1], \"%Y-%m-%d_%H-%M-%S-%f\") for i in starling_wavs]\n",
    "st_wavs = np.array(starling_wavs)[np.argsort(st_labs)]\n",
    "st_labs = np.array(st_labs)[np.argsort(st_labs)]\n",
    "st_days = np.array([lab.strftime('%d%m%y') for lab in st_labs])\n",
    "st_day_wavs = [np.array(starling_wavs)[st_days == i] for i in np.unique(st_days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:48.073768Z",
     "start_time": "2019-03-23T01:23:47.998371Z"
    }
   },
   "outputs": [],
   "source": [
    "len(bf_day_wavs), len(st_day_wavs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:54.893082Z",
     "start_time": "2019-03-23T01:23:48.076543Z"
    }
   },
   "outputs": [],
   "source": [
    "wav_loc = human_wavs[0][0]\n",
    "rate, data= wavfile.read(wav_loc)\n",
    "hparams['sample_rate'] = rate\n",
    "_mel_basis = sg._build_mel_basis(hparams) # build a basis function if you are using a mel spectrogram\n",
    "spec = sg.melspectrogram(data, hparams, _mel_basis)\n",
    "fig, ax = plt.subplots(figsize=(30,3))\n",
    "ax.matshow(spec[:,5000:10000], interpolation=None, aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:23:54.905954Z",
     "start_time": "2019-03-23T01:23:54.901081Z"
    }
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return(x - np.min(x))/(np.max(x)-np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:24:01.192866Z",
     "start_time": "2019-03-23T01:23:54.908673Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_wav(wav_loc, hparams, time_bin, _mel_basis):\n",
    "    \"\"\" slice a wav into chunks of a given (tim_bin (seconds)) time length\n",
    "    \"\"\"\n",
    "    # load wav\n",
    "    print(wav_loc.split('.')[-1])\n",
    "    if wav_loc.split('.')[-1] == 'wav':\n",
    "        rate, data= wavfile.read(wav_loc)\n",
    "    elif wav_loc.split('.')[-1] == 'cbin':\n",
    "        data, rate = load_cbin(wav_loc)\n",
    "    # set sample rate of wav\n",
    "    hparams['sample_rate'] = rate\n",
    "    # create mel basis\n",
    "    _mel_basis = sg._build_mel_basis(hparams) # build a basis function if you are using a mel spectrogram\n",
    "    # load wav\n",
    "    spec = sg.melspectrogram(data, hparams, _mel_basis)\n",
    "    # get number of frames for each time bin\n",
    "    frames_per_time_bin = fptb= int(time_bin/(hparams['frame_shift_ms']/1000))\n",
    "    spec_samples = [spec[:, i*fptb:(i+1)*fptb] for i in range(int(np.shape(spec)[1]/fptb))]\n",
    "    return np.array(norm(spec_samples)*255).astype(np.uint8)\n",
    "test = process_wav(wav_loc, hparams, time_bin=1.0, _mel_basis=_mel_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:24:01.475669Z",
     "start_time": "2019-03-23T01:24:01.201585Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute MI across timescales and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:24:01.524792Z",
     "start_time": "2019-03-23T01:24:01.502722Z"
    }
   },
   "outputs": [],
   "source": [
    "def MI_raw_audio(dset, _mel_basis, wav_files, n_clusters = 100, time_bin=1.0, verbosity=0, n_jobs=20, seconds_dist = 100):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    song_pieces = []\n",
    "    \n",
    "    for wf_day in wav_files:\n",
    "        # split into pieces\n",
    "        with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "            song_pieces_day = [parallel(\n",
    "                delayed(process_wav)(wav_loc, hparams, time_bin, _mel_basis) \n",
    "                     for wav_loc in tqdm(wf_day, leave=False, desc='wav segmentation'))]\n",
    "            song_pieces.append(np.vstack([np.vstack(i) for i in song_pieces_day]))\n",
    "\n",
    "    # stack pieces into one long list\n",
    "    song_pieces_filt = np.vstack(song_pieces)\n",
    "    # flatten\n",
    "    song_pieces_filt_flat = song_pieces_filt.reshape((np.shape(song_pieces_filt)[\n",
    "                                                     0], np.shape(song_pieces_filt)[1]*np.shape(song_pieces_filt)[2]))\n",
    "    # prep kmeans clustering\n",
    "    mbk = sklearn.cluster.MiniBatchKMeans(init='k-means++', n_clusters=n_clusters, batch_size=100,\n",
    "                                          n_init=10, max_no_improvement=10, verbose=0,\n",
    "                                          random_state=0)\n",
    "    \n",
    "    # fit kmeans\n",
    "    clusters = mbk.fit(song_pieces_filt_flat)\n",
    "    \n",
    "    # MI should be computed up until the median list len\n",
    "    list_lens = [len(i) for i in song_pieces]\n",
    "    \n",
    "    d2c = int(seconds_dist/time_bin)\n",
    "    distances = np.arange(1, np.median(d2c).astype(int))\n",
    "    \n",
    "    # split labels into original sequences\n",
    "    seqs = [mbk.labels_[int(np.sum(list_lens[:i])):int(\n",
    "        np.sum(list_lens[:i+1]))] for i, llen in enumerate(list_lens)]\n",
    "    \n",
    "    # calculate Mutual information\n",
    "    (MI, var_MI), (MI_shuff, MI_shuff_var) = it.sequential_mutual_information(seqs,\n",
    "                                                                  distances,\n",
    "                                                                  n_jobs=n_jobs,\n",
    "                                                                  verbosity=verbosity,\n",
    "                                                                  n_shuff_repeats=1, estimate=True)\n",
    "\n",
    "    return [dset, time_bin, MI, var_MI, MI_shuff, MI_shuff_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:24:01.995823Z",
     "start_time": "2019-03-23T01:24:01.528024Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 100\n",
    "MI_raw = pd.DataFrame(columns = ['dset', 'time_bin', 'MI', 'var_MI', 'MI_shuff', 'MI_shuff_var'])\n",
    "for (dset, wav_files) in tqdm([['starling', st_day_wavs], ['bengalese finch', bf_day_wavs], ['english', human_wavs]], desc=\"dataset\"):\n",
    "    print(dset)\n",
    "    for time_bin in tqdm([1.0, 0.1, 0.01], leave=False, desc=\"time_bin\"):\n",
    "        results = MI_raw_audio(dset, _mel_basis, wav_files, n_clusters = n_clusters, time_bin=time_bin, verbosity=0, n_jobs=20, seconds_dist = 100)\n",
    "        MI_raw.loc[len(MI_raw)] = results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:24:01.998304Z",
     "start_time": "2019-03-23T01:23:42.159Z"
    }
   },
   "outputs": [],
   "source": [
    "MI_raw.to_pickle(DATA_DIR/'MI_DF/MI_raw.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:24:01.999647Z",
     "start_time": "2019-03-23T01:23:42.165Z"
    }
   },
   "outputs": [],
   "source": [
    "MI_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T01:24:02.001014Z",
     "start_time": "2019-03-23T01:23:42.172Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols = 3, nrows = 3, figsize = (20,10))\n",
    "for dsi, dset in enumerate(['english', 'bengalese finch', 'starling']):\n",
    "    for tbi, time_bin in enumerate([0.01, 0.1, 1.0]):\n",
    "        ax = axs[tbi, dsi]\n",
    "        if dset == 'english':\n",
    "            color = LCOL_DICT[dset]\n",
    "        elif dset == 'bengalese finch':\n",
    "            color = BCOL_DICT['BF']\n",
    "        elif dset == 'starling':\n",
    "            color = BCOL_DICT['Starling']\n",
    "\n",
    "        subset_MI_DF = MI_raw[(MI_raw.dset == dset) & (MI_raw.time_bin == time_bin)]\n",
    "        sig = subset_MI_DF.MI.values[0] - subset_MI_DF.MI_shuff.values[0]\n",
    "        distances = np.arange(1,len(sig)+1)*time_bin\n",
    "\n",
    "        ax.scatter(distances, sig, alpha = 1, s=40, color=color)\n",
    "        ax.plot(distances, sig, alpha = 0, color=color)\n",
    "\n",
    "        ax.tick_params(which='both', direction='in', labelsize=14, pad=10)\n",
    "        ax.tick_params(which='major', length=10, width =3)\n",
    "        ax.tick_params(which='minor', length=5, width =2)\n",
    "        ax.set_xscale( \"log\" , basex=10)\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(3)\n",
    "            ax.spines[axis].set_color('k')\n",
    "\n",
    "        ax.set_xlim([10e-4, 100])\n",
    "\n",
    "        ax.set_xscale( \"log\" , basex=10)\n",
    "        ax.set_yscale( \"log\" , basey=10)\n",
    "    axs[0,dsi].set_title(dset.capitalize(), fontsize=18)\n",
    "    axs[2,dsi].set_xlabel('Distance between elements (seconds)', fontsize=18)\n",
    "\n",
    "axs[1,0].set_ylabel('Mutual Information (bits)', fontsize=18)\n",
    "\n",
    "save_fig(FIGURE_DIR/'spectrogram_MI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
