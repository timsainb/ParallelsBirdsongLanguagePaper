{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate MI for each language and plot goodness of fit by length of analysis\n",
    "1. load datasets\n",
    "2. calculate MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:14.967507Z",
     "start_time": "2019-03-09T06:06:12.546084Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from parallelspaper.config.paths import DATA_DIR, FIGURE_DIR\n",
    "from parallelspaper.speech_datasets import LCOL_DICT\n",
    "from parallelspaper import information_theory as it \n",
    "from tqdm.autonotebook import tqdm\n",
    "from parallelspaper import model_fitting as mf\n",
    "from parallelspaper.utils import save_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:20.013671Z",
     "start_time": "2019-03-09T06:06:14.971190Z"
    }
   },
   "outputs": [],
   "source": [
    "german_seqs = pd.read_pickle(DATA_DIR/'speech_seq_df/GECO_seq_df.pickle')\n",
    "italian_seqs = pd.read_pickle(DATA_DIR/'speech_seq_df/AsiCA_seq_df.pickle')\n",
    "english_seqs = pd.read_pickle(DATA_DIR/'speech_seq_df/BUCKEYE_seq_df.pickle')\n",
    "japanese_seqs = pd.read_pickle(DATA_DIR/'speech_seq_df/CSJ_seq_df.pickle')\n",
    "\n",
    "seq_df = pd.concat([german_seqs, italian_seqs, english_seqs, japanese_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:20.021911Z",
     "start_time": "2019-03-09T06:06:20.015639Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:20.143103Z",
     "start_time": "2019-03-09T06:06:20.023936Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_df[['language', 'levels']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:20.252555Z",
     "start_time": "2019-03-09T06:06:20.144999Z"
    }
   },
   "outputs": [],
   "source": [
    "subsets = [\n",
    "    ['german', 'speaker/word/phoneme'],\n",
    "    ['italian', 'speaker/word/phoneme'],\n",
    "    ['english', 'speaker/utterance/word/phonetic'],\n",
    "    ['japanese', 'speaker/word/phonemes'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:20.378827Z",
     "start_time": "2019-03-09T06:06:20.254490Z"
    }
   },
   "outputs": [],
   "source": [
    "# subset only the main analyses\n",
    "subset_seq_df = pd.concat([seq_df[(seq_df.language == l) & (seq_df.levels == lev)] for l, lev in subsets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:20.495247Z",
     "start_time": "2019-03-09T06:06:20.380873Z"
    }
   },
   "outputs": [],
   "source": [
    "len(subset_seq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MI\n",
    "- for each unit calculate MI within speaker, and within speaker when shuffling words when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:20.611069Z",
     "start_time": "2019-03-09T06:06:20.497154Z"
    }
   },
   "outputs": [],
   "source": [
    "distances = np.arange(1,1001)\n",
    "verbosity = 0; n_jobs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:06:20.719025Z",
     "start_time": "2019-03-09T06:06:20.613135Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatlist(list_of_lists):\n",
    "    return [val for sublist in list_of_lists for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:14:47.002187Z",
     "start_time": "2019-03-09T06:06:20.720814Z"
    }
   },
   "outputs": [],
   "source": [
    "MI_DF = pd.DataFrame(columns=['language', 'unit', 'analysis', 'MI', 'MI_shuff', 'distances', 'MI_var', 'MI_shuff_var', 'n_elements'])\n",
    "\n",
    "for idx, (language, levels, data) in tqdm(subset_seq_df.iterrows(), total = len(subset_seq_df)):\n",
    "    levels = levels.split('/')\n",
    "    \n",
    "    # buckeye has an additional 'utterance' level to ignore\n",
    "    if language == 'english':\n",
    "        data = [flatlist(speaker) for speaker in data]\n",
    "        if len(levels) == 4:\n",
    "            levels = np.array(levels)[[0,2,3]].tolist()\n",
    "        elif len(levels) == 3:\n",
    "            levels = np.array(levels)[[0,2]].tolist()\n",
    "            \n",
    "    if len(levels) == 2:\n",
    "        # speakers is the highest level or organization so just compute MI\n",
    "        units = data\n",
    "        (MI, var_MI), (MI_shuff, MI_shuff_var) = it.sequential_mutual_information(units, distances, n_jobs = n_jobs, verbosity = verbosity)\n",
    "        MI_DF.loc[len(MI_DF)] = [language, levels[-1], 'session', MI, MI_shuff, distances, var_MI, MI_shuff_var, len(flatlist(units))]\n",
    "\n",
    "    else:   \n",
    "        # concatenate across words, compute MI\n",
    "        units = np.array([flatlist(i) for i in data])\n",
    "        (MI, var_MI), (MI_shuff, MI_shuff_var) = it.sequential_mutual_information(units, distances, n_jobs = n_jobs, verbosity = verbosity)\n",
    "        MI_DF.loc[len(MI_DF)] = [language, levels[-1], 'session', MI, MI_shuff, distances, var_MI, MI_shuff_var, len(flatlist(units))]\n",
    "\n",
    "    # save dataframe\n",
    "    MI_DF.to_pickle(DATA_DIR / 'MI_DF/language/language_MI_DF_long.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:14:47.012863Z",
     "start_time": "2019-03-09T06:14:47.006365Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "n_jobs = 20; verbosity = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:14:47.113416Z",
     "start_time": "2019-03-09T06:14:47.016321Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fit(language, d, distances, sig):\n",
    "    results_power, results_exp, results_pow_exp, best_fit_model = mf.fit_models(\n",
    "        distances[:d], sig[:d])\n",
    "    R2_exp, R2_concat, R2_power, AICc_exp, AICc_pow, AICc_concat = mf.fit_results(\n",
    "        sig[:d], distances[:d],  results_exp, results_power, results_pow_exp)\n",
    "\n",
    "    y_model = mf.get_y(mf.pow_exp_decay, results_pow_exp, distances)\n",
    "    y_pow = mf.get_y(mf.powerlaw_decay, results_pow_exp, distances)\n",
    "    y_exp = mf.get_y(mf.exp_decay, results_pow_exp, distances)\n",
    "\n",
    "    R2_exp_comp = mf.r2(sig[:d] - y_pow[:d], y_exp[:d] -\n",
    "                        results_pow_exp.params['intercept'].value, distances[:d], logscaled=True)\n",
    "    s = sig[:d] - y_exp[:d]\n",
    "    m = y_pow[:d]-results_pow_exp.params['intercept'].value\n",
    "    mask = s > 0\n",
    "    R2_pow_comp = mf.r2(s[mask], m[mask], distances[:d][mask], logscaled=True)\n",
    "    # print(R2_pow_comp)\n",
    "    #plt.plot(distances[:d], mf.residuals(s, m,distances[:d]))\n",
    "\n",
    "    AICc_exp_comp = mf.AICc(d, len(results_exp.params), sig[:d] - y_pow[:d], y_exp[:d] -\n",
    "                            results_pow_exp.params['intercept'].value, distances[:d], logscaled=True)\n",
    "    AICc_pow_comp = mf.AICc(d, len(results_power.params),\n",
    "                            sig[:d] - y_exp[:d], y_pow[:d]-results_pow_exp.params['intercept'].value, distances[:d], logscaled=True)\n",
    "    return (language, d, R2_exp, R2_concat, R2_power, AICc_exp, AICc_pow, \n",
    "            AICc_concat, R2_pow_comp, R2_exp_comp, AICc_exp_comp, AICc_pow_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T06:15:47.281680Z",
     "start_time": "2019-03-09T06:14:47.117651Z"
    }
   },
   "outputs": [],
   "source": [
    "# aic / r2 for individual components\n",
    "fit_df = []\n",
    "\n",
    "columns = ['language', 'd', 'R2_exp', 'R2_concat', 'R2_power', 'AICc_exp', 'AICc_pow', \n",
    "                                 'AICc_concat', 'R2_pow_comp', 'R2_exp_comp',  'AICc_exp_comp', 'AICc_pow_comp']\n",
    "\n",
    "for axi, (idx, row) in enumerate(MI_DF.sort_values(by=['unit','analysis']).iterrows()):\n",
    "    language = row.language\n",
    "    sig = row.MI-row.MI_shuff\n",
    "    with Parallel(n_jobs=n_jobs, verbose=verbosity) as parallel:\n",
    "        x = parallel(\n",
    "            delayed(get_fit)(language, d, row.distances, sig)\n",
    "                 for d in tqdm(np.unique(np.linspace(16,1000, 200).astype(int))))\n",
    "    \n",
    "    fit_df_lang = pd.DataFrame(x, columns = columns)\n",
    "    fit_df.append(fit_df_lang)\n",
    "fit_df = pd.concat(fit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T07:54:15.407668Z",
     "start_time": "2019-03-09T07:54:15.377520Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_df.to_pickle(DATA_DIR / 'MI_DF/language/fit_df_long.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T07:54:02.514492Z",
     "start_time": "2019-03-09T07:54:02.476215Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
