{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate MI for each unit/language\n",
    "1. load datasets\n",
    "2. calculate MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:15.569325Z",
     "start_time": "2019-04-12T03:45:06.032642Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from parallelspaper.config.paths import DATA_DIR, FIGURE_DIR\n",
    "from parallelspaper.speech_datasets import LCOL_DICT\n",
    "\n",
    "from parallelspaper import information_theory as it \n",
    "from parallelspaper.quickplots import plot_model_fits\n",
    "from tqdm.autonotebook import tqdm\n",
    "from parallelspaper import model_fitting as mf\n",
    "from parallelspaper.utils import save_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:15.608830Z",
     "start_time": "2019-04-12T03:45:15.580429Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.159869Z",
     "start_time": "2019-04-12T03:45:15.619660Z"
    }
   },
   "outputs": [],
   "source": [
    "english_seqs = pd.read_pickle(DATA_DIR/'speech_seq_df/BUCKEYE_seq_df.pickle')\n",
    "japanese_seqs = pd.read_pickle(DATA_DIR/'speech_seq_df/CSJ_seq_df.pickle')\n",
    "seq_df = pd.concat([english_seqs, japanese_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.190869Z",
     "start_time": "2019-04-12T03:45:04.726Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.199375Z",
     "start_time": "2019-04-12T03:45:04.733Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_df[['language', 'levels']].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset relevant utterance datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.207284Z",
     "start_time": "2019-04-12T03:45:04.739Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatlist(list_of_lists):\n",
    "    return [val for sublist in list_of_lists for val in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.215207Z",
     "start_time": "2019-04-12T03:45:04.742Z"
    }
   },
   "outputs": [],
   "source": [
    "# subset english sequences\n",
    "eng_utterance_seq_df = seq_df.query('levels == \"speaker/utterance/word/phonetic\"')\n",
    "idx, language, levels, data = eng_utterance_seq_df.reset_index().loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.222567Z",
     "start_time": "2019-04-12T03:45:04.745Z"
    }
   },
   "outputs": [],
   "source": [
    "### Shuffling\n",
    "# phones < utterance < speakers \n",
    "eng_utterances = [[flatlist(utterance) for utterance in speaker] for speaker in data]\n",
    "# utterance lengths\n",
    "eng_utterance_lens = [len(utterance) for utterance in flatlist(eng_utterances)]\n",
    "# shuffle order of phones within utterance\n",
    "eng_utterance_shuffled_within = [[np.random.permutation(utterance) for utterance in speaker] for speaker in eng_utterances]\n",
    "# shuffle order of utterance within speakers\n",
    "eng_utterance_shuffled_between = [np.random.permutation(speaker) for speaker in eng_utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.229760Z",
     "start_time": "2019-04-12T03:45:04.747Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.median(eng_utterance_lens), np.mean(eng_utterance_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.236805Z",
     "start_time": "2019-04-12T03:45:04.749Z"
    }
   },
   "outputs": [],
   "source": [
    "# subset jap sequences\n",
    "jap_utterance_seq_df = seq_df.query('levels == \"speaker/IPU/phonemes\"')\n",
    "idx, language, levels, data = jap_utterance_seq_df.reset_index().loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.244128Z",
     "start_time": "2019-04-12T03:45:04.752Z"
    }
   },
   "outputs": [],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.252100Z",
     "start_time": "2019-04-12T03:45:04.754Z"
    }
   },
   "outputs": [],
   "source": [
    "### Shuffling\n",
    "jap_utterances = data\n",
    "# shuffle order of phones within utterance\n",
    "jap_utterance_shuffled_within = [[np.random.permutation(utterance) for utterance in speaker] for speaker in jap_utterances]\n",
    "# shuffle order of utterance within speakers\n",
    "jap_utterance_shuffled_between = [np.random.permutation(speaker) for speaker in jap_utterances]\n",
    "# utterance lengths\n",
    "jap_utterance_lens = [len(utterance) for utterance in flatlist(jap_utterances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.259685Z",
     "start_time": "2019-04-12T03:45:04.756Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.median(jap_utterance_lens), np.mean(jap_utterance_lens))\n",
    "# utterance lengths\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(12,3))\n",
    "ax[0].hist(jap_utterance_lens, bins = np.arange(1,200));\n",
    "ax[0].set_title('Jap utterance sequence lens')\n",
    "\n",
    "ax[1].hist(eng_utterance_lens, bins = np.arange(1,200));\n",
    "ax[1].set_title('English utterance sequence lens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MI\n",
    "- for each unit calculate MI within speaker, and within speaker when shuffling words when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.266703Z",
     "start_time": "2019-04-12T03:45:04.758Z"
    }
   },
   "outputs": [],
   "source": [
    "distances = np.arange(1,101)\n",
    "verbosity = 0; n_jobs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.273390Z",
     "start_time": "2019-04-12T03:45:04.762Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate MI\n",
    "MI_DF = pd.DataFrame(columns=['language', 'unit', 'analysis', 'MI', 'MI_shuff', 'distances', 'MI_var', 'MI_shuff_var', 'n_elements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.280541Z",
     "start_time": "2019-04-12T03:45:04.766Z"
    }
   },
   "outputs": [],
   "source": [
    "# MI for shuffle within utterance\n",
    "units = [flatlist(i) for i in eng_utterance_shuffled_within]\n",
    "(MI, var_MI), (MI_shuff, MI_shuff_var) = it.sequential_mutual_information(units, distances, n_jobs = n_jobs, verbosity = verbosity)\n",
    "MI_DF.loc[len(MI_DF)] = ['english', 'phone', 'shuffled_within_utterance', MI, MI_shuff, distances, var_MI, MI_shuff_var, len(flatlist(units))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.287814Z",
     "start_time": "2019-04-12T03:45:04.769Z"
    }
   },
   "outputs": [],
   "source": [
    "# MI for shuffle between utterance\n",
    "units = [flatlist(i) for i in eng_utterance_shuffled_between]\n",
    "(MI, var_MI), (MI_shuff, MI_shuff_var) = it.sequential_mutual_information(units, distances, n_jobs = n_jobs, verbosity = verbosity)\n",
    "MI_DF.loc[len(MI_DF)] = ['english', 'phone', 'shuffled_between_utterance', MI, MI_shuff, distances, var_MI, MI_shuff_var, len(flatlist(units))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.294823Z",
     "start_time": "2019-04-12T03:45:04.773Z"
    }
   },
   "outputs": [],
   "source": [
    "# MI for shuffle within utterance\n",
    "units = [flatlist(i) for i in jap_utterance_shuffled_within]\n",
    "(MI, var_MI), (MI_shuff, MI_shuff_var) = it.sequential_mutual_information(units, distances, n_jobs = n_jobs, verbosity = verbosity)\n",
    "MI_DF.loc[len(MI_DF)] = ['japanese', 'phoneme', 'shuffled_within_utterance', MI, MI_shuff, distances, var_MI, MI_shuff_var, len(flatlist(units))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.302274Z",
     "start_time": "2019-04-12T03:45:04.776Z"
    }
   },
   "outputs": [],
   "source": [
    "# MI for only between utterance\n",
    "units = [flatlist(i) for i in jap_utterance_shuffled_between]\n",
    "(MI, var_MI), (MI_shuff, MI_shuff_var) = it.sequential_mutual_information(units, distances, n_jobs = n_jobs, verbosity = verbosity)\n",
    "MI_DF.loc[len(MI_DF)] = ['japanese', 'phoneme', 'shuffled_between_utterance', MI, MI_shuff, distances, var_MI, MI_shuff_var, len(flatlist(units))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.309596Z",
     "start_time": "2019-04-12T03:45:04.779Z"
    }
   },
   "outputs": [],
   "source": [
    "# prep for new data in dataframe\n",
    "MI_DF = MI_DF.assign(**{i:np.nan for i in ['exp_results', 'pow_results', 'concat_results',\n",
    "     'R2_exp', 'R2_concat', 'R2_power', 'AICc_exp',\n",
    "     'AICc_concat', 'AICc_power', 'bestfitmodel', 'curvature', 'min_peak']})\n",
    "MI_DF['curvature'] = MI_DF['curvature'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.316581Z",
     "start_time": "2019-04-12T03:45:04.784Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 100 # max distance for computation\n",
    "for idx, row in tqdm(MI_DF.iterrows(), total=len(MI_DF)):\n",
    "    # get signal\n",
    "    sig = np.array(row.MI-row.MI_shuff)\n",
    "    distances = row.distances\n",
    "    sig = sig\n",
    "    \n",
    "    # fit models\n",
    "    results_power, results_exp, results_pow_exp, best_fit_model = mf.fit_models(distances, sig)\n",
    "    \n",
    "    # get fit results\n",
    "    R2_exp, R2_concat, R2_power, AICc_exp, \\\n",
    "        AICc_pow, AICc_concat = mf.fit_results(sig, distances, \n",
    "                                              results_exp, results_power,\n",
    "                                              results_pow_exp)\n",
    "    \n",
    "    # get model y\n",
    "    distances_mod = np.logspace(0,np.log10(n), base=10, num=1000)\n",
    "    if best_fit_model == 'pow_exp':\n",
    "        y_model = mf.get_y(mf.pow_exp_decay, results_pow_exp, distances_mod)\n",
    "    elif best_fit_model == 'exp':\n",
    "        y_model = mf.get_y(mf.exp_decay, results_exp, distances_mod)\n",
    "    elif best_fit_model == 'pow':\n",
    "        y_model = mf.get_y(mf.powerlaw_decay, results_power, distances_mod)\n",
    "    \n",
    "    # get curvature of model_y\n",
    "    curvature_model = mf.curvature(np.log(y_model))\n",
    "    \n",
    "    # if the best fit model is pow_exp, then grab the min peak\n",
    "    if best_fit_model == 'pow_exp':\n",
    "        # get peaks of curvature\n",
    "        peaks = np.where((\n",
    "            (curvature_model[:-1] < curvature_model[1:])[1:] & (curvature_model[1:] < curvature_model[:-1])[:-1]\n",
    "        ))\n",
    "        min_peak = peaks[0][0]\n",
    "    else:\n",
    "        min_peak = np.nan\n",
    "\n",
    "    # get save model fit results to MI_DF\n",
    "    MI_DF.loc[idx, np.array(['exp_results', 'pow_results', 'concat_results',\n",
    "                         'R2_exp', 'R2_concat', 'R2_power', 'AICc_exp',\n",
    "                         'AICc_concat', 'AICc_power', 'bestfitmodel', 'curvature', 'min_peak'])] = [\n",
    "        results_exp, results_power, results_pow_exp,\n",
    "        R2_exp, R2_concat, R2_power, AICc_exp,\n",
    "        AICc_concat, AICc_pow, best_fit_model,\n",
    "        curvature_model, min_peak\n",
    "    ]\n",
    "\n",
    "    # quick plot of model fitting\n",
    "    plot_model_fits(row.MI, row.MI_shuff, distances, results_power, results_exp, results_pow_exp)\n",
    "\n",
    "    print(row.unit, row.analysis, best_fit_model, row.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.323250Z",
     "start_time": "2019-04-12T03:45:04.786Z"
    }
   },
   "outputs": [],
   "source": [
    "MI_DF.to_pickle((DATA_DIR / 'MI_DF/language/language_MI_DF_fitted-utterance.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot shuffling analysis within vs between for utterances in japanese and english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:45:21.330138Z",
     "start_time": "2019-04-12T03:45:04.789Z"
    }
   },
   "outputs": [],
   "source": [
    "fontsize=19\n",
    "yoff=-.20\n",
    "ncol = 4\n",
    "nrow = len(MI_DF)//ncol\n",
    "zoom = 5\n",
    "fig, axs = plt.subplots(ncols=ncol, nrows=nrow, figsize=zoom*np.array([ncol,nrow]))\n",
    "for axi, (idx, row) in enumerate(MI_DF.sort_values(by=['analysis', 'language', 'unit']).iterrows()):\n",
    "    ax = axs.flatten()[axi]\n",
    "    \n",
    "    color = LCOL_DICT[row.language]\n",
    "    sig = np.array(row.MI-row.MI_shuff)\n",
    "    distances = row.distances\n",
    "    sig = sig\n",
    "    distances = distances\n",
    "    # get signal limits\n",
    "    sig_lims = np.log([np.min(sig[sig>0]), np.nanmax(sig)])\n",
    "    sig_lims = [sig_lims[0] - (sig_lims[1]-sig_lims[0])/10,\n",
    "                    sig_lims[1] + (sig_lims[1]-sig_lims[0])/10]\n",
    "            \n",
    "    if axi%ncol == 0:\n",
    "            ax.set_ylabel('Mutual Information (bits)', labelpad=5, fontsize=fontsize)\n",
    "            ax.yaxis.set_label_coords(yoff,0.5)\n",
    "    if axi >= (nrow-1)*ncol:      \n",
    "        ax.set_xlabel('Distance (phones)', labelpad=5, fontsize=fontsize)\n",
    "    \n",
    "    \n",
    "    # plot real data\n",
    "    ax.scatter(distances, sig, alpha = 1, s=40, color=color)\n",
    "    \n",
    "    best_fit_model = np.array(['exp','pow','pow_exp'])[np.argmin(row[['AICc_exp', 'AICc_power', 'AICc_concat']].values)]\n",
    "    \n",
    "    # set title\n",
    "    analysis = 'within utterance' if row.analysis == 'shuffled_within_utterance' else 'between utterance'\n",
    "    model_type = {'pow_exp': 'composite', 'exp': 'exponential', 'pow':'power law'}[best_fit_model]\n",
    "    ax.set_title(' | '.join([row.language.capitalize(), analysis, model_type]), fontsize=fontsize)\n",
    "    \n",
    "    # plot model\n",
    "    distances_model = np.logspace(0,np.log10(distances[-1]), base=10, num=1000)\n",
    "    \n",
    "    if best_fit_model == 'pow_exp':\n",
    "        ax.axvline(distances_model[int(row.min_peak)], lw=3,alpha=0.5, color=color, ls='dashed')\n",
    "        \n",
    "    if best_fit_model == 'pow_exp':\n",
    "        # model data\n",
    "        #row.concat_results.params.intercept = 0\n",
    "        y_model = mf.get_y(mf.pow_exp_decay, row.concat_results, distances_model)\n",
    "        y_pow = mf.get_y(mf.powerlaw_decay, row.concat_results, distances_model)\n",
    "        y_exp = mf.get_y(mf.exp_decay, row.concat_results, distances_model)\n",
    "\n",
    "        ax.plot(distances_model, y_pow, ls='dotted', color= 'k', lw=5, alpha=0.5)\n",
    "        ax.plot(distances_model, y_exp-row.concat_results.params['intercept'].value, ls='dashed', color= 'k', lw=5, alpha=0.5)\n",
    "\n",
    "        # plot modelled data\n",
    "        ax.plot(distances_model, y_model, alpha = 0.5, lw=10, color=color)\n",
    "    \n",
    "    elif best_fit_model == 'pow':\n",
    "        y_model = mf.get_y(mf.powerlaw_decay, row.pow_results, distances_model)\n",
    "        # plot modelled data\n",
    "        ax.plot(distances_model, y_model, alpha = 0.5, lw=10, color=color)\n",
    "        \n",
    "        \n",
    "    elif best_fit_model == 'exp':\n",
    "        y_model = mf.get_y(mf.exp_decay, row.exp_results, distances_model)\n",
    "        # plot modelled data\n",
    "        ax.plot(distances_model, y_model, alpha = 0.5, lw=10, color=color)\n",
    "        \n",
    "    # axis params\n",
    "    ax.set_xlim([distances[0], distances[-1]])\n",
    "    sig_lims[0] = np.log(10e-6)\n",
    "    ax.set_ylim(np.exp(sig_lims))\n",
    "    ax.tick_params(which='both', direction='in', labelsize=14, pad=10)\n",
    "    ax.tick_params(which='major', length=10, width =3)\n",
    "    ax.tick_params(which='minor', length=5, width =2)\n",
    "    ax.set_xscale( \"log\" , basex=10)\n",
    "    ax.set_yscale( \"log\" , basey=10)\n",
    "    ax.set_xticks([])\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(3)\n",
    "        ax.spines[axis].set_color('k')\n",
    "    \n",
    "    ax.set_xlim([1,100])\n",
    "    ax.set_xticks([1,10,100])\n",
    "    ax.set_xticklabels(['1','10','100'])\n",
    "    \n",
    "    \n",
    "save_fig(FIGURE_DIR/'speech_shuffle_utterance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
