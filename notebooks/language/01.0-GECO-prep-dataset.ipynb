{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare GECO (german dataset)\n",
    "1. grab linguistic units from dataset\n",
    "2. grab dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T19:13:18.648671Z",
     "start_time": "2019-03-03T19:13:18.477101Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from parallelspaper.speech_datasets import prep_GECO\n",
    "from parallelspaper.config.paths import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:18:45.664905Z",
     "start_time": "2019-03-03T07:18:45.659024Z"
    }
   },
   "outputs": [],
   "source": [
    "GECO_DIR = '/mnt/cube/Datasets/German/GECO/textgrids/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:38:42.436673Z",
     "start_time": "2019-03-03T07:38:42.430374Z"
    }
   },
   "outputs": [],
   "source": [
    "text_grids = glob(GECO_DIR+'*.textGrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T08:36:24.280261Z",
     "start_time": "2019-03-03T08:34:12.002756Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(track_durations, word_durations, phone_durations, syll_durations, all_words, all_sylls, all_phones) = prep_GECO(text_grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T08:40:14.811234Z",
     "start_time": "2019-03-03T08:40:11.994098Z"
    }
   },
   "outputs": [],
   "source": [
    "num_phonemes = len(np.concatenate(np.concatenate(all_phones)))\n",
    "num_words = len(np.concatenate(all_words))\n",
    "word_durations_s = word_durations\n",
    "word_length_phones = [len(i) for i in np.concatenate(all_phones)]\n",
    "phone_duration_s = np.concatenate(phone_durations)\n",
    "unique_phones = len(np.unique(np.concatenate(np.concatenate(all_phones))))\n",
    "unique_words = len(np.unique(np.concatenate(all_words)))\n",
    "utterance_length_phones = None\n",
    "n_sessions = len(all_words)\n",
    "session_durations = track_durations\n",
    "total_duration = np.sum(session_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T08:40:17.478103Z",
     "start_time": "2019-03-03T08:40:17.368076Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame([[\n",
    "        num_phonemes,\n",
    "        num_words,\n",
    "        word_durations_s,\n",
    "        word_length_phones,\n",
    "        phone_duration_s,\n",
    "        unique_phones,\n",
    "        unique_words,\n",
    "        utterance_length_phones,\n",
    "        n_sessions,\n",
    "        session_durations,\n",
    "        total_duration\n",
    "    ]],\n",
    "    columns = [\n",
    "        'num_phonemes',\n",
    "        'num_words',\n",
    "        'word_durations_s',\n",
    "        'word_length_phones',\n",
    "        'phone_duration_s',\n",
    "        'unique_phones',\n",
    "        'unique_words',\n",
    "        'utterance_length_phones',\n",
    "        'n_sessions',\n",
    "        'session_durations',\n",
    "        'total_duration'\n",
    "        ])\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T19:13:20.999170Z",
     "start_time": "2019-03-03T19:13:20.787855Z"
    }
   },
   "outputs": [],
   "source": [
    "# statistics for this language\n",
    "stats_df.to_pickle((DATA_DIR / 'stats_df/GECO_stats_df.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sequence dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T03:17:01.874196Z",
     "start_time": "2019-03-04T03:17:01.863685Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_df = pd.DataFrame(columns = ['language', 'levels', 'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T03:17:02.432464Z",
     "start_time": "2019-03-04T03:17:02.418940Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_df.loc[len(seq_df)] = ['german', 'speaker/word/phoneme', all_phones]\n",
    "seq_df.loc[len(seq_df)] = ['german', 'speaker/word', all_words]\n",
    "seq_df.loc[len(seq_df)] = ['german', 'speaker/word/sylls', all_sylls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T03:17:03.743718Z",
     "start_time": "2019-03-04T03:17:02.932513Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_df.to_pickle((DATA_DIR / 'speech_seq_df/GECO_seq_df.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
